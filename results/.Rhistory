}
inv <- solve(x$get(), ...)
x$setinv(inv)
return(inv)
}
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
set <- function(y){
x <<- y
inv <<- NULL
}
get <- function() x
setinv <- function(i) inv <<- i
getinv <- function() inv
list(set = set, get = get, setinv = setinv, getinv = getinv)
}
cacheSolve <- function(x, ...) {
inv <- x$getinv()
if(!is.null(inv)){
message("getting cached data")
return(inv)
}
inv <- solve(x$get(), ...)
x$setinv(inv)
return(inv)
}
test = function(mat){
## @mat: an invertible matrix
temp = makeCacheMatrix(mat)
start.time = Sys.time()
cacheSolve(temp)
dur = Sys.time() - start.time
print(dur)
start.time = Sys.time()
cacheSolve(temp)
dur = Sys.time() - start.time
print(dur)
}
set.seed(1110201)
r = rnorm(1000000)
mat1 = matrix(r, nrow=1000, ncol=1000)
test(mat1)
## Matrix inverse computation is a costly operation and
## there is some benefit to caching already computed values
## rather than computing repeatedly. The following has a pair
## of functions that calculates and caches the inverse of a martix.
## This function creates a special "matrix" object that can cache its inverse.
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
set <- function(y){
x <<- y
inv <<- NULL
}
get <- function() x
setinv <- function(i) inv <<- i
getinv <- function() inv
list(set = set, get = get, setinv = setinv, getinv = getinv)
}
## This function computes the inverse of the special "matrix" returned by
## makeCacheMatrix above. If the inverse has already been calculated
## (and the matrix has not changed), then cacheSolve should retrieve the
## inverse from the cache.
cacheSolve <- function(x, ...) {
inv <- x$getinv()
if(!is.null(inv)){
message("getting cached data")
return(inv)
}
inv <- solve(x$get(), ...)
x$setinv(inv)
return(inv)
}
test = function(mat){
## @mat: an invertible matrix
temp = makeCacheMatrix(mat)
start.time = Sys.time()
cacheSolve(temp)
dur = Sys.time() - start.time
print(dur)
start.time = Sys.time()
cacheSolve(temp)
dur = Sys.time() - start.time
print(dur)
}
set.seed(1110201)
r = rnorm(1000000)
mat1 = matrix(r, nrow=1000, ncol=1000)
test(mat1)
## Matrix inverse computation is a costly operation and
## there is some benefit to caching already computed values
## rather than computing repeatedly. The following has a pair
## of functions that calculates and caches the inverse of a martix.
## This function creates a special "matrix" object that can cache its inverse.
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
set <- function(y){
x <<- y
inv <<- NULL
}
get <- function() x
setinv <- function(i) inv <<- i
getinv <- function() inv
list(set = set, get = get, setinv = setinv, getinv = getinv)
}
## This function computes the inverse of the special "matrix" returned by
## makeCacheMatrix above. If the inverse has already been calculated
## (and the matrix has not changed), then cacheSolve should retrieve the
## inverse from the cache.
cacheSolve <- function(x, ...) {
inv <- x$getinv()
if(!is.null(inv)){
message("getting cached data")
return(inv)
}
inv <- solve(x$get(), ...)
x$setinv(inv)
return(inv)
}
?mtcars
?factor
str(mtcars)
?mtcars
mtcars$cyl <- factor(mtcars$cyl)
?mtcars
str(mtcars)
mtcars$am <- factor(mtcars$am)
levels(mtcars$am) <- c('-auto', '-manual')
str(mtcars)
head(mtcars)
fit <- lm(mpg ~ cyl + wt, mtcars)
fit
summary(fit)
summar(fit)$coef[3,1]
summary(fit)$coef[3,1]
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
hatvalues(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
influence.measures(fit)$infmat[5, 'dfb.x']
influence.measures(fit)
install.packages("rmarkdown")
install.packages("knitr")
library(rmarkdown)
library(knitr)
data(mtcars)
summary(mtcars)
str(mtcars)
?mtcars
library(MASS)
?shuttle
str(shuttle)
?glm
set.seed(1)
rpois(5,2)
system.time()
?system.time
library(fpc)
install.packages("fpc")
R.home()
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url, dest="/media/sf_shared/data/data.csv", method="curl")
download.file(url, dest="/media/sf_shared/data/data.csv", method="auto")
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(url, dest='/media/sf_shared/data/data.csv', method="auto")
download.file(url, dest='/media/sf_shared/data/data.csv', method="curl")
download.file(url, dest='/media/sf_shared/data/data.csv', method="curl")
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(url, dest='/media/sf_shared/data/data.csv', method="curl")
install.packages("Rcurl")
install.packages("RCurl")
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(url, dest='/media/sf_shared/data/data.csv', method="curl")
download.file(url, dest='/media/sf_shared/data/data.csv')
url <- 'http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(url, dest='/media/sf_shared/data/data.csv')
data <- read.csv('/media/sf_shared/data/data.csv')
str(data)
sum(!is.na(data$VAL[data$VAL==24]))
data$VAL
data$VAL[data$VAL==24]
is.na(data$VAL[data$VAL==24])
!is.na(data$VAL[data$VAL==24])
sum(!is.na(data$VAL[data$VAL==24]))
data$FES
summary(data)
library(xlsx)
install.packages("xlsx")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
file.download(url, destfile="/media/sf_shared/data/nga.xlsx")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(url, destfile="/media/sf_shared/data/nga.xlsx")
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(url, destfile="/media/sf_shared/data/nga.xlsx")
dateDownloaded <- date()
library(xlsx)
install.packages("xlsx")
install.packages("xlsx")
library(xlsx)
install.packages("xlsx")
install.packages("rJava")
install.packages("rJava")
install.packages("rJava")
install.packages("xlsx")
library(xlsx)
data <- read.xlsx("/media/sf_shared/data/nga.xlsx", sheetIndex=1, header=TRUE, colIndex=colIndex, rowIndex=rowIndex)
colIndex <- 7:15
rowIndex <- 18:23
data <- read.xlsx("/media/sf_shared/data/nga.xlsx", sheetIndex=1, header=TRUE, colIndex=colIndex, rowIndex=rowIndex)
sum(data$Zip*data$Ext, na.rm=TRUE)
head(data)
data
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(url, destfile="/media/sf_shared/data/rest.xlsx")
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(url, destfile="/media/sf_shared/data/rest.xlsx")
dateDownloaded <- date()
library(xlsx)
doc <- xmlTreeParse(url, useInternal=TRUE)
library(XML)
install.packages("XML")
library(XML)
doc <- xmlTreeParse(url, useInternal=TRUE)
rootNode <- xmlRoot(doc)
sum(xpathSApply(rootNode, "//zipcode", xmlValue)==21231)
rootNode
library(DmWR)
library(DMwR)
install.packages("DMwR")
R.home()
install.packages("DMwR")
library(DMwR)
iris2 <- iris[,1:4]
outlier.scores <- lofactor(iris2, k=5)
plot(density(outlier.scores))
outliers <- order(outlier.scores, decreasing=T)[1:5]
print(outliers)
iris2
iris
head(iris)
head(iris2)
?lofactor
print(outliers)
str(outlier.scores)
?lm
?lag
library(UsingR)
library(httr)
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("quiz2", "ddb0d599de51ccd02f4c", secret="6af1109f6ecf442d292425087d49bb13d9bbe9c9")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
require(httpuv)
install.packages("httpuv")
require(httpuv)
?oauth_app
myapp <- oauth_app("quiz2", "ddb0d599de51ccd02f4b", secret="fa90897b4692a3dec8a7c3a4a53138453471cdc7")
ithub_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
GET https://github.com/login/oauth/authorize
https://github.com/login/oauth/authorize
POST https://github.com/login/oauth/access_token
myapp <- oauth_app("quiz2", "0463ff665ded97541bb1",secret="ef31f4d5c259aee936814ba41484a0ecb1f1aa38")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
output
list(output[[4]]$name, output[[4]]$created_at)
str(output)
list(output[[1]]$name, output[[4]]$created_at)
list(output[[2]]$name, output[[2]]$created_at)
list(output[[3]]$name, output[[3]]$created_at)
summary(output)
head(output)
list(output[[4]]$name, output[[4]]$created_at)
list(output[[5]]$name, output[[5]]$created_at)
list(output[[6]]$name, output[[6]]$created_at)
?sqldf
??sqldf
connection <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(connection)
close(connection)
c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
library(knitr)
getwd()
?stringdist
?stringdistmatrix
library(stringdist)
?xyplot
library(xyplot)
?bwplot
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
library(stringdist)
stringdist
stringdist('MARTHA','MATHRA',method='jw',p=0.1)
stringdist('MARTHA','MATHRA',method='jw',p=0)
stringdist('sclcnas401','slcnas401',method='jw',p=0)
stringdist('sclcnas401','slcnas401',method='jw',p=0.)
stringdist('sclcnas401','slcnas401',method='jw',p=0.1)
stringdist('sclcnas401','slcnas401',method='jw',p=0.9)
stringdist('sclcnas401','slcnas401',method='jw',p=0.25)
stringdist('sclcnas401','slcnas401',method='jw',p=0.01)
stringdist('sclcnas401','slcnas401',method='jw',p=0.1)
stringdist('sclcnas401','slcnas401',method='osa')
stringdist('slcnas401','slcnas401',method='osa')
stringdist('slcnas401','dennas401',method='osa')
stringdist('slcnas401','nasden401',method='osa')
stringdist('slcnas401','nasden401',method='lv')
stringdist('slcnas401','sclcnas401',method='lv')
stringdist('slcnas401','blrnas401',method='lv')
stringdist('slcnas401','blrnas401',method='lcs')
stringdist('slcnas401','blrnas401',method='qgram')
install.packages("locfit")
locfit
stringdist
library(stringdis)
library(stringdist)
?stringdist
stringdist('MARTHA','MATHRA',method='jw',p=0.1)
stringdist('MARTHA','MATHRA',method='jw',weight=c(1, 1, 0.5) p=0.1)
stringdist('MARTHA','MATHRA',method='jw',weight=c(1, 1, 0.5), p=0.1)
stringdist('MARTHA','MATHRA',method='jw',weight=c(1, 1, 0.5), p=0.2)
stringdist('MARTHA','MATHRA',method='jw',weight=c(1, 1, 0.5), p=0.2)
stringdist('abcdef','abcghi',method='jw',weight=c(1, 1, 0.5), p=0.2)
stringdist('abcdef','abcghi',method='jw',weight=c(1, 1, 0.5))
stringdist('MARTHA','MATHRA',method='jw')
stringdist('MARTHA','MATHRA',method='jw', p=0.2)
stringdist('MARTHA','MATHRA',method='jw', weight=c(1, 1, 0.5), p=0.2)
stringdist('MARTHA','MATHRA',method='jw', weight=c(1, 1, 0.5))
stringdist('MARTHA','MATHRA',method='jw', weight=c(1, 1, 0.5))
stringdist('MARTHA','MATHRA',method='jw', weight=c(1, 1, 1))
stringdist('MARTHA','MATHRA',method='jw')
stringdist('abcdef','abcghi',method='jw')
stringdist('MARTHA','MATHRA',method='jw')
stringdist('abcdef','abcghi',method='jw')
stringdist('abcdef','abcghi',method='jw', p=0.1)
stringdist('abcdef','abcfed',method='jw', p=0.1)
stringdist('abcdef','abcfed',method='jw', p=0.1)
stringdist('abcdef','abcfed',method='jw')
stringdist('abcdef','abcfed',method='jw', p=0)
stringdist('abcdef','abcfed',method='jw', p=0)
stringdist('DIXON','DICKSONX',method='jw', p=0)
stringdist('DIXON','DICKSONX',method='jw', p=0.1)
library(strindist)
library(stringdist)
stringdist('abc logged in', 'def logged in', method="cosine")
stringdist('abc logged in', 'abc logged in', method="cosine")
stringdist('abc logged in', 'abc also logged in', method="cosine")
stringdist('abc logged in', 'def logged in', method="cosine")
stringdist(' oraem, slciapa.us.oracle.com, User logged in via CLI', 'fusovmb, slcac670.us.oracle.com, User logged in via CLI', method="cosine")
stringdist('oraem, slciapa.us.oracle.com, User logged in via CLI', 'fusovmb, slcac670.us.oracle.com, User logged in via CLI', method="cosine")
stringdist('oraem, slciapa.us.oracle.com, User logged in via CLI', 'fusovmb, slcac670.us.oracle.com, User logged in via UI', method="cosine")
?mahalanobis
require(graphics)
ma <- cbind(1:6, 1:3)
(S <-  var(ma))
ma
S
mahalanobis(c(0, 0), 1:2, S)
x <- matrix(rnorm(100*3), ncol = 3)
stopifnot(mahalanobis(x, 0, diag(ncol(x))) == rowSums(x*x))
Sx <- cov(x)
D2 <- mahalanobis(x, colMeans(x), Sx)
x
D2
plot(density(D2, bw = 0.5),
main="Squared Mahalanobis distances, n=100, p=3") ; rug(D2)
qqplot(qchisq(ppoints(100), df = 3), D2,
main = expression("Q-Q plot of Mahalanobis" * ~D^2 *
" vs. quantiles of" * ~ chi[3]^2))
abline(0, 1, col = 'gray')
abline(0, 1, col = 'blue')
install.packages("emdist")
library(emdist)
?emdist
?emd
A <- matrix(1:6 / sum(1:6), 2)
B <- matrix(c(0, 0, 0, 0, 0, 1), 2)
emd2d(A, B)
A <- matrix(1:6 / sum(1:6), 2)
B <- matrix(c(0, 0, 0, 0, 0, 1), 2)
emd2d(A, B)
A
B
A <- matrix(1:6)
A
B <- matrix(1:6)
A
B
emd2d(A, B)
B <- matrix(1:8)
emd2d(A, B)
A <- matrix(c(1,2,3,4,5,6))
B <- matrix(c(1,2,3,4,5,6))
A
B
emd2d(A, B)
B <- matrix(c(1,2,3,4,5,0))
emd2d(A, B)
?emdr
emdr(A, B)
emdr(A, B,extrapolate=NA, flows=FALSE, dist="euclidean")
emd2d(A, B,, 0.1)
library(AppliedPredictiveModeling)
install.packages("library(AppliedPredictiveModeling)")
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library(abind)
library(arm)
install.packages("arm")
library(arm)
library(caret)
library(kernlab)
library(klarR)
library(klaR)
library(rattle)
install.packages("rattle")
library(randomForest)
install.packages(randomForest)
install.packages("randomForest")
install.packages(randomForest)
library(randomForest)
library(rpart)
train <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
setwd("/home/dkumares/git_code/prac_ml/ExcerciseManner")
train <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
nearzero <- nearZeroVar(train, saveMetrics=TRUE)
train <- train[, !nearzero$nzv]
nearzero
nearzero$nzv
str(nearzero)
train
head(train)
canRemove <- sapply(colnames(train), function(x) if (sum(is.na(train[, x]))>0.50*nrow(train)) {return (TRUE)}
else{
return(FALSE)})
train <- train[, !canRemove]
head(train)
names(train)
corr <- caret::findCorrelation(cor(train[, -53]), cutoff=0.8)
names(train)[corr]
Hcorr <- caret::findCorrelation(cor(train[, -53]), cutoff=0.8)
names(train)[Hcorr]
train <- train[, -(1:6)]
names(train)
Hcorr <- caret::findCorrelation(cor(train[, -53]), cutoff=0.8)
names(train)[Hcorr]
tcontrol <- trainControl(method="cv", number = 7, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
randomForest <- train(classe ~ ., data = train, method = "rf", trControl= tc)
nn <- train(classe ~ ., data = train, method = "nnet", trControl= tc, verbose=FALSE)
logitboost <- train(classe ~ ., data = train, method = "LogitBoost", trControl= tc)
svmR <- train(classe ~ ., data = train, method = "svmRadial", trControl= tc)
svmL <- train(classe ~ ., data = train, method = "svmLinear", trControl= tc)
bayesglm <- train(classe ~ ., data = train, method = "bayesglm", trControl= tc)
tcontrol <- trainControl(method="cv", number = 7, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
randomForest <- train(classe ~ ., data = train, method = "rf", trControl= tcontrol)
tcontrol <- trainControl(method="cv", number = 7, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
randomForest <- train(classe ~ ., data = train, method = "rf", trControl= tcontrol)
svmR <- train(classe ~ ., data = train, method = "svmRadial", trControl= tcontrol)
rfPred <- predict(rf, test)
svmRPred <- predict(svmR, test)
rfPred <- predict(randomForest, test)
svmRPred <- predict(svmR, test)
rfPred
setwd("/home/dkumares/git_code/prac_ml/ExcerciseManner/results")
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(rfPred)
pml_write_files(svmRPred)
